.catalog:
  name: "Prometheus"
  version: "1.0.2"
  description: "Prometheus Monitoring Solution"
  minimum_rancher_version: v0.59.0
  questions:
  - variable: PROMETHEUS_CONFIG
    description: "Prometheus config"
    label: "Prometheus config"
    type: "multiline"
    required: true
    default: |
      global:
        scrape_interval:     15s
        evaluation_interval: 15s
        external_labels:
            monitor: 'exporter-metrics'

      scrape_configs:
      - job_name: 'HostsMetrics'
        dns_sd_configs:
        - names:
          - node-exporter
          refresh_interval: 15s
          type: A
          port: 9100

      - job_name: 'ContainerMetrics'
        dns_sd_configs:
        - names:
          - ranch-eye
          refresh_interval: 15s
          type: A
          port: 9104

      - job_name: 'rancher-api'
        static_configs:
          - targets:
            - 'prometheus-rancher-exporter:9010'

      - job_name: 'Prometheus'
        static_configs:
          - targets:
            - '127.0.0.1:9090'
  - variable: ALERTMANAGER_CONFIG
    description: "Alert Manager config"
    label: "Alert Manager config"
    type: "multiline"
    required: true
    default: |
      global:
        # The smarthost and SMTP sender used for mail notifications.
        smtp_smarthost: 'localhost:25'
        smtp_from: 'alertmanager@example.org'
        smtp_auth_username: 'alertmanager'
        smtp_auth_password: 'password'
        # The auth token for Hipchat.
        hipchat_auth_token: '1234556789'
        # Alternative host for Hipchat.
        hipchat_url: 'https://hipchat.foobar.org/'

      # The directory from which notification templates are read.
      templates:
      - '/etc/alertmanager/template/*.tmpl'

      # The root route on which each incoming alert enters.
      route:
        # The labels by which incoming alerts are grouped together. For example,
        # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
        # be batched into a single group.
        group_by: ['alertname', 'cluster', 'service']

        # When a new group of alerts is created by an incoming alert, wait at
        # least 'group_wait' to send the initial notification.
        # This way ensures that you get multiple alerts for the same group that start
        # firing shortly after another are batched together on the first
        # notification.
        group_wait: 30s

        # When the first notification was sent, wait 'group_interval' to send a batch
        # of new alerts that started firing for that group.
        group_interval: 5m

        # If an alert has successfully been sent, wait 'repeat_interval' to
        # resend them.
        repeat_interval: 3h

        # A default receiver
        receiver: team-X-mails

        # All the above attributes are inherited by all child routes and can
        # overwritten on each.

        # The child route trees.
        routes:
        # This routes performs a regular expression match on alert labels to
        # catch alerts that are related to a list of services.
        - match_re:
            service: ^(foo1|foo2|baz)$
          receiver: team-X-mails
          # The service has a sub-route for critical alerts, any alerts
          # that do not match, i.e. severity != critical, fall-back to the
          # parent node and are sent to 'team-X-mails'
          routes:
          - match:
              severity: critical
            receiver: team-X-pager
        - match:
            service: files
          receiver: team-Y-mails

          routes:
          - match:
              severity: critical
            receiver: team-Y-pager

        # This route handles all alerts coming from a database service. If there's
        # no team to handle it, it defaults to the DB team.
        - match:
            service: database
          receiver: team-DB-pager
          # Also group alerts by affected database.
          group_by: [alertname, cluster, database]
          routes:
          - match:
              owner: team-X
            receiver: team-X-pager
          - match:
              owner: team-Y
            receiver: team-Y-pager


      # Inhibition rules allow to mute a set of alerts given that another alert is
      # firing.
      # We use this to mute any warning-level notifications if the same alert is
      # already critical.
      inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        # Apply inhibition if the alertname is the same.
        equal: ['alertname', 'cluster', 'service']


      receivers:
      - name: 'team-X-mails'
        email_configs:
        - to: 'team-X+alerts@example.org'

      - name: 'team-X-pager'
        email_configs:
        - to: 'team-X+alerts-critical@example.org'
        pagerduty_configs:
        - service_key: <team-X-key>

      - name: 'team-Y-mails'
        email_configs:
        - to: 'team-Y+alerts@example.org'

      - name: 'team-Y-pager'
        pagerduty_configs:
        - service_key: <team-Y-key>

      - name: 'team-DB-pager'
        pagerduty_configs:
        - service_key: <team-DB-key>
      - name: 'team-X-hipchat'
        hipchat_configs:
        - auth_token: <auth_token>
          room_id: 85
          message_format: html
          notify: true

prometheus:
  scale: 1
  metadata:
    prometheus-config: |
      ${PROMETHEUS_CONFIG}
  health_check:
    port: 9090
    interval: 5000
    unhealthy_threshold: 3
    request_line: ''
    healthy_threshold: 2
    response_timeout: 5000

alertmanager:
  scale: 1
  metadata:
    alertmanager-config: |
      ${ALERTMANAGER_CONFIG}

influxdb:
  scale: 1
  health_check:
    port: 8086
    interval: 5000
    unhealthy_threshold: 3
    request_line: ''
    healthy_threshold: 2
    response_timeout: 5000

grafana:
  scale: 1
  health_check:
    port: 3000
    interval: 5000
    unhealthy_threshold: 3
    request_line: ''
    healthy_threshold: 2
    response_timeout: 5000

prometheus-rancher-exporter:
  scale: 1
  upgrade_strategy:
    start_first: true
  health_check:
    port: 9010
    interval: 5000
    unhealthy_threshold: 3
    request_line: ''
    healthy_threshold: 2
    response_timeout: 5000